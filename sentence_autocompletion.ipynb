{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf025750-4099-4249-80d1-c46981c81fdf",
   "metadata": {},
   "source": [
    "# Sentence Autocompletion Model\n",
    "https://huggingface.co/docs/transformers/notebooks \n",
    "https://github.com/huggingface/blog/blob/main/notebooks/02_how_to_generate.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ec7c83b-e936-426b-aa1a-4ebb5d97bf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80c6138a-d73d-4419-8c34-c3613909647a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter start of sentence:  my experience with software engineering\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "my experience with software engineering is that it's a very difficult job. It's not easy to get a job that you want to do.\n",
      "\n",
      "I've been in the software engineering field for about 10 years. I've been in the software engineering\n"
     ]
    }
   ],
   "source": [
    "# encode context the generation is conditioned on\n",
    "start = input(\"enter start of sentence: \")\n",
    "input_ids = tokenizer.encode(start, return_tensors='pt')\n",
    "\n",
    "# generate text until the output length (which includes the context length) reaches 50\n",
    "greedy_output = model.generate(input_ids, max_length=50)\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a74fde5-dea8-424a-ab72-91404a67fb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: my experience with software engineering is that it's hard to know what you're talking about when you talk about software development.\n",
      "\n",
      "I'm not going to go into too much detail here, but I'll just say that I've had a lot of\n",
      "1: my experience with software engineering is that it's hard to know what you're talking about when you talk about software development.\n",
      "\n",
      "I'm not going to go into too much detail here, but I'll just say that I'm a software engineer.\n",
      "2: my experience with software engineering is that it's hard to know what you're talking about when you talk about software development.\n",
      "\n",
      "I'm not going to go into too much detail here, but I'll just say that I'm a software engineer,\n",
      "3: my experience with software engineering is that it's hard to know what you're talking about when you talk about software development.\n",
      "\n",
      "I'm not going to go into too much detail here, but I'll just say that I'm a software engineer and\n",
      "4: my experience with software engineering is that it's hard to know what you're talking about when you talk about software development.\n",
      "\n",
      "I'm not going to go into too much detail here, but I'll just say that I've been working on a\n"
     ]
    }
   ],
   "source": [
    "# activate beam search and early_stopping\n",
    "beam_outputs = model.generate(\n",
    "    input_ids,  \n",
    "    max_length=50, \n",
    "    num_beams=5, \n",
    "    no_repeat_ngram_size=2,\n",
    "    num_return_sequences=5,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, beam_output in enumerate(beam_outputs):\n",
    "  print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5411f797-1984-41f6-a4f1-e9218c497341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "my experience with software engineering, when it came to the digital ish, I had the idea that the best thing to do would be to build something that can be used to make a digital ish. That's when I signed up.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# activate sampling and deactivate top_k by setting top_k sampling to 0\n",
    "sample_output = model.generate(\n",
    "    input_ids, \n",
    "    do_sample=True, \n",
    "    max_length=50, \n",
    "    top_k=0,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc4bbfa8-8c5b-4caf-b7f9-8feaaf378bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: my experience with software engineering, I wanted to share the process with my company. Here's how you can share the process with others.\n",
      "\n",
      "One more thing: I started using open-source software after seeing it make the rounds on Facebook and Google\n",
      "1: my experience with software engineering when it comes to my work is that it's very personal. I was always a big fan of Microsoft, and had the opportunity to work with them. It's hard to take things away when you have your mind on something\n",
      "2: my experience with software engineering: \"The best way to learn is to build it and let it grow. Build it. You can make it better, as long as you have the necessary skills to understand how it works.\" (My own experience with that\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
    "sample_outputs = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True, \n",
    "    max_length=50, \n",
    "    top_k=50, \n",
    "    top_p=0.95, \n",
    "    num_return_sequences=3\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "57431414-6b90-4514-abca-ff02c4c8c5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter start of sentence:  my skills in swe include\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: my skills in swe include the occasional little-used, little-used tool that can be used as a backstop, or as a tool that's less important to someone else but that you think is important to you.\n",
      "1: my skills in swe include running and juggling.\n",
      "2: my skills in swe include, an 8mm (2x) 3/4 in.\n"
     ]
    }
   ],
   "source": [
    "# generate 3 options for sentence completion, stopping at the end of the sentence\n",
    "start = input(\"enter start of sentence: \")\n",
    "input_ids = tokenizer.encode(start, return_tensors='pt')\n",
    "\n",
    "sample_outputs = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    max_length=50,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    num_return_sequences=3,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "    # Decode the output, stopping at the first EOS token\n",
    "    decoded_text = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
    "    first_sentence = decoded_text.split('.')[0] + '.'\n",
    "    print(\"{}: {}\".format(i, first_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090f5a49-ecb7-40d3-90e8-0239f5ea7796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0103730-b5d5-4eb9-ae2b-03489dac8296",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
